{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework and bake-off: pragmatic color descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Christopher Potts\"\n",
    "__version__ = \"CS224u, Stanford, Summer 2022\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Overview](#Overview)\n",
    "1. [Set-up](#Set-up)\n",
    "1. [All two-word examples as a dev corpus](#All-two-word-examples-as-a-dev-corpus)\n",
    "1. [Dev dataset](#Dev-dataset)\n",
    "1. [Random train–test split for development](#Random-train–test-split-for-development)\n",
    "1. [Question 1: Improve the tokenizer [1 point]](#Question-1:-Improve-the-tokenizer-[1-point])\n",
    "1. [Use the tokenizer](#Use-the-tokenizer)\n",
    "1. [Question 2: Improve the color representations [1 point]](#Question-2:-Improve-the-color-representations-[1-point])\n",
    "1. [Use the color representer](#Use-the-color-representer)\n",
    "1. [Initial model](#Initial-model)\n",
    "1. [Question 3: GloVe embeddings [1 point]](#Question-3:-GloVe-embeddings-[1-point])\n",
    "1. [Try the GloVe representations](#Try-the-GloVe-representations)\n",
    "1. [Question 4: Color context [3 points]](#Question-4:-Color-context-[3-points])\n",
    "1. [Your original system [3 points]](#Your-original-system-[3-points])\n",
    "1. [Bakeoff [1 point]](#Bakeoff-[1-point])\n",
    "1. [Submission Instruction](#Submission-Instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This homework and associated bake-off are oriented toward building an effective system for generating color descriptions that are pragmatic in the sense that they would help a reader/listener figure out which color was being referred to in a shared context consisting of a target color (whose identity is known only to the describer/speaker) and a set of distractors.\n",
    "\n",
    "The notebook [colors_overview.ipynb](colors_overview.ipynb) should be studied before work on this homework begins. That notebook provides backgroud on the task, the dataset, and the modeling code that you will be using and adapting.\n",
    "\n",
    "The homework questions are more open-ended than previous ones have been. Rather than asking you to implement pre-defined functionality, they ask you to try to improve baseline components of the full system in ways that you find to be effective. As usual, this culminates in a prompt asking you to develop a novel system for entry into the bake-off. In this case, though, the work you do for the homework will likely be directly incorporated into that system (not required, but an efficient way to work at the very least)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [colors_overview.ipynb](colors_overview.ipynb) for set-up in instructions and other background details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colors import ColorsCorpusReader\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_color_describer import ContextualColorDescriber\n",
    "from torch_color_describer import create_example_dataset\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "import utils\n",
    "from utils import START_SYMBOL, END_SYMBOL, UNK_SYMBOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.fix_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS_SRC_FILENAME = os.path.join(\n",
    "    \"data\", \"colors\", \"filteredCorpus.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All two-word examples as a dev corpus\n",
    "\n",
    "So that you don't have to sit through excessively long training runs during development, I suggest working with the two-word-only subset of the corpus until you enter into the late stages of system testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_corpus = ColorsCorpusReader(\n",
    "    COLORS_SRC_FILENAME,\n",
    "    word_count=2,\n",
    "    normalize_colors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_examples = list(dev_corpus.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This subset has about one-third the examples of the full corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13890"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We __should__ worry that it's not a fully representative sample. Most of the descriptions in the full corpus are shorter, and a large proportion are longer. So this dataset is mainly for debugging, development, and general hill-climbing. All findings should be validated on the full dataset at some point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev dataset\n",
    "\n",
    "The first step is to extract the raw color and raw texts from the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dev_rawcols, dev_texts = zip(*[[ex.colors, ex.contents] for ex in dev_examples])'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"dev_rawcols, dev_texts = zip(*[[ex.colors, ex.contents] for ex in dev_examples])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw color representations are suitable inputs to a model, but the texts are just strings, so they can't really be processed as-is. Question 1 asks you to do some tokenizing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random train–test split for development\n",
    "\n",
    "For the sake of development runs, we create a random train–test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dev_rawcols_train, dev_rawcols_test, dev_texts_train, dev_texts_test =     train_test_split(dev_rawcols, dev_texts)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"dev_rawcols_train, dev_rawcols_test, dev_texts_train, dev_texts_test = \\\n",
    "    train_test_split(dev_rawcols, dev_texts)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Improve the tokenizer [1 point]\n",
    "\n",
    "This is the first required question – the first required modification to the default pipeline.\n",
    "\n",
    "The function `tokenize_example` simply splits its string on whitespace and adds the required start and end symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def bert_tokenize(texts):\\n    example_ids = bert_tokenizer.batch_encode_plus(\\n        texts,\\n        add_special_tokens=True,\\n        return_attention_mask=True,\\n        padding = 'longest')\\n    return example_ids\\n    input_ids = example_ids['input_ids']\\n    attention = example_ids['attention_mask']\\n    return input_ids, attention\\n    # tokens = bert_tokenizer.convert_ids_to_tokens(input_ids), attention\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "weights_name = 'bert-base-uncased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(weights_name)\n",
    "\n",
    "def tokenize_example(s, verbose=False):\n",
    "    encoding = bert_tokenizer.encode(s)\n",
    "    return bert_tokenizer.convert_ids_to_tokens(encoding)\n",
    "\n",
    "\"\"\"def bert_tokenize(texts):\n",
    "    example_ids = bert_tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        padding = 'longest')\n",
    "    return example_ids\n",
    "    input_ids = example_ids['input_ids']\n",
    "    attention = example_ids['attention_mask']\n",
    "    return input_ids, attention\n",
    "    # tokens = bert_tokenizer.convert_ids_to_tokens(input_ids), attention\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the tokenizer is working, run the following cell to tokenize your inputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use only the train set to derive a vocabulary for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_from_bert(bert_tokens):\n",
    "    vocab = {UNK_SYMBOL}\n",
    "    for row in bert_tokens['input_ids']:\n",
    "        vocab = vocab.union({tok for tok in bert_tokenizer.convert_ids_to_tokens(row)})\n",
    "    vocab.remove('[PAD]')\n",
    "    return list(sorted(vocab))\n",
    "\n",
    "# bert_vocab = get_vocab_from_bert(bert_tokens_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important that the `UNK_SYMBOL` is included somewhere in this list. In test examples, words not seen in training will be mapped to `UNK_SYMBOL`. \n",
    "\n",
    "Conceptual note: If you model's vocab is the same as your train vocab, then `UNK_SYMBOL` will never be encountered during training, so it will be a random vector at test time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Improve the color representations [1 point]\n",
    "\n",
    "This is the second required pipeline improvement for the assignment. \n",
    "\n",
    "The following functions do nothing at all to the raw input colors we get from the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def represent_color_context(colors):\n",
    "\n",
    "    # Improve me!\n",
    "\n",
    "    return [represent_color(color) for color in colors]\n",
    "\n",
    "\n",
    "def represent_color(color):\n",
    "    \n",
    "    [H, S, V] = convert_hls_to_hsv(color)\n",
    "    \n",
    "    representation = []\n",
    "    for j, k, l in product((0, 1, 2), repeat = 3):\n",
    "        f_jkl = np.exp(-2j*np.pi*(j*H + k*S + l*V))\n",
    "        representation += [f_jkl.real, f_jkl.imag]\n",
    "\n",
    "    return representation\n",
    "\n",
    "def convert_hls_to_hsv(color):\n",
    "    [H, L, S] = color\n",
    "    \n",
    "    H_new = H\n",
    "    V_new = L + S * min(L, 1-L)\n",
    "    S_new = 2 * (1 - L/V_new) if V_new != 0 else 0\n",
    "    \n",
    "    return [H_new, S_new, V_new]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following test seeks to ensure only that the output of your `represent_color_context` will be compatible with the models we are creating:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the color representer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell just runs your `represent_color_context` on the train and test sets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our preprocessing steps are complete, and we can fit a first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_color_describer import Decoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BertColorContextDecoder(Decoder):\n",
    "    def __init__(self, color_dim, idx2bertids, *args, **kwargs):\n",
    "        self.color_dim = color_dim\n",
    "        self.weights_name = 'bert-base-uncased'\n",
    "        bert_model = BertModel.from_pretrained(self.weights_name)\n",
    "        self.embed_dim = bert_model.embeddings.word_embeddings.embedding_dim\n",
    "        self.idx2bertids = idx2bertids\n",
    "        self.attention_mask = None\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.bert = bert_model\n",
    "        self.bert.train()\n",
    "        \n",
    "        self.rnn = nn.GRU(\n",
    "            input_size = self.embed_dim + color_dim,\n",
    "            hidden_size = self.hidden_dim,\n",
    "            batch_first = True)\n",
    "        \n",
    "    def get_embeddings(self, word_seqs, target_colors=None):\n",
    "        # The key question is what is word_seqs, I think it should\n",
    "        # probably be BERT tokens, then we can feed these into the\n",
    "        # the bert model and get the reps, basically disconnect from\n",
    "        # vocab, this means reworking the tokenize pipeline, the issue\n",
    "        # before was just that we were tokenizing the vocab, not the\n",
    "        # examples\n",
    "        \n",
    "        bert_id_seqs = self.idx2bertids[word_seqs]\n",
    "        \n",
    "        attention_mask = torch.zeros(word_seqs.shape)\n",
    "        attention_mask[bert_id_seqs.nonzero(as_tuple=True)] = 1\n",
    "        \n",
    "        # with torch.no_grad():\n",
    "        token_embeddings = self.bert(word_seqs, attention_mask=self.attention_mask).last_hidden_state\n",
    "            \n",
    "        color_embeddings = (torch.stack([\n",
    "            torch.repeat_interleave(\n",
    "                target_color.reshape(1, -1),\n",
    "                token_embeddings.shape[1],\n",
    "                dim=0)\n",
    "            for target_color in target_colors], dim=0))\n",
    "        \n",
    "        # print(color_embeddings.shape)\n",
    "        \n",
    "        return torch.cat((token_embeddings, color_embeddings), dim=2)\n",
    "        \n",
    "        \n",
    "\n",
    "class ColorContextDecoder(Decoder):\n",
    "    def __init__(self, color_dim, *args, **kwargs):\n",
    "        self.color_dim = color_dim\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # Fix the `self.rnn` attribute:\n",
    "        ##### YOUR CODE HERE\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size = self.embed_dim + color_dim,\n",
    "            hidden_size = self.hidden_dim,\n",
    "            batch_first = True)\n",
    "\n",
    "\n",
    "    def get_embeddings(self, word_seqs, target_colors=None, attention_masks=None):\n",
    "        \"\"\"\n",
    "        You can assume that `target_colors` is a tensor of shape\n",
    "        (m, n), where m is the length of the batch (same as\n",
    "        `word_seqs.shape[0]`) and n is the dimensionality of the\n",
    "        color representations the model is using. The goal is\n",
    "        to attached each color vector i to each of the tokens in\n",
    "        the ith sequence of (the embedded version of) `word_seqs`.\n",
    "\n",
    "        \"\"\"\n",
    "        ##### YOUR CODE HERE\n",
    "        \n",
    "        word_embeddings = self.embedding(word_seqs)\n",
    "        \n",
    "        color_embeddings = (torch.stack([\n",
    "            torch.repeat_interleave(\n",
    "                target_color.reshape(1, -1),\n",
    "                word_embeddings.shape[1],\n",
    "                dim=0)\n",
    "            for target_color in target_colors], dim=0))\n",
    "        \n",
    "        \n",
    "        return torch.cat((word_embeddings, color_embeddings), dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 is the most demanding of the steps in terms of tensor wrangling. It's important to have a clear idea of what you are trying to achieve and to unit test `get_embeddings` so that you can check that it has realized your vision. The following test should help with that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2__: Modify the `EncoderDecoder`. For this, you just need to make a small change to the `forward` method: extract the target colors from `color_seqs` and feed them to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_color_describer import EncoderDecoder\n",
    "\n",
    "class ColorizedEncoderDecoder(EncoderDecoder):\n",
    "\n",
    "    def forward(self,\n",
    "            color_seqs,\n",
    "            word_seqs,\n",
    "            seq_lengths=None,\n",
    "            hidden=None,\n",
    "            targets=None):\n",
    "        if hidden is None:\n",
    "            hidden = self.encoder(color_seqs)\n",
    "\n",
    "        # Extract the target colors from `color_seqs` and\n",
    "        # feed them to the decoder, which already has a\n",
    "        # `target_colors` keyword.\n",
    "\n",
    "        ##### YOUR CODE HERE\n",
    "        output, hidden = self.decoder(\n",
    "            word_seqs,\n",
    "            seq_lengths=seq_lengths,\n",
    "            hidden=hidden,\n",
    "            target_colors=color_seqs[:,2],\n",
    "        )        \n",
    "\n",
    "\n",
    "\n",
    "        # Your decoder will return `output, hidden` pairs; the\n",
    "        # following will handle the two return situations that\n",
    "        # the code needs to consider -- training and prediction.\n",
    "        if self.training:\n",
    "            return output\n",
    "        else:\n",
    "            return output, hidden\n",
    "        \n",
    "class BertEncoderDecoder(EncoderDecoder):\n",
    "    \n",
    "    def forward(self,\n",
    "            color_seqs,\n",
    "            word_seqs,\n",
    "            # attention_masks,\n",
    "            seq_lengths=None,\n",
    "            hidden=None,\n",
    "            targets=None):\n",
    "        if hidden is None:\n",
    "            hidden = self.encoder(color_seqs)\n",
    "\n",
    "        # Extract the target colors from `color_seqs` and\n",
    "        # feed them to the decoder, which already has a\n",
    "        # `target_colors` keyword.\n",
    "        \n",
    "        ##### YOUR CODE HERE\n",
    "        output, hidden = self.decoder(\n",
    "            word_seqs,\n",
    "            seq_lengths=seq_lengths,\n",
    "            hidden=hidden,\n",
    "            target_colors=color_seqs[:,2],\n",
    "            # attention_masks=attention_masks\n",
    "        )        \n",
    "\n",
    "\n",
    "\n",
    "        # Your decoder will return `output, hidden` pairs; the\n",
    "        # following will handle the two return situations that\n",
    "        # the code needs to consider -- training and prediction.\n",
    "        if self.training:\n",
    "            return output\n",
    "        else:\n",
    "            return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3__: Finally, as in the examples in [Modifying the core model](colors_overview.ipynb#Modifying-the-core-model), you need to modify the `build_graph` method of `ContextualColorDescriber` so that it uses your new `ColorContextDecoder` and `ColorizedEncoderDecoder`. Here's starter code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_color_describer import Encoder, ColorDataset\n",
    "\n",
    "BERT_EMBED_DIM = 768\n",
    "\n",
    "class ColorizedInputDescriber(ContextualColorDescriber):\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        # We didn't modify the encoder, so this is\n",
    "        # just copied over from the original:\n",
    "        encoder = Encoder(\n",
    "            color_dim=self.color_dim,\n",
    "            hidden_dim=self.hidden_dim)\n",
    "\n",
    "        # Use your `ColorContextDecoder`, making sure\n",
    "        # to pass in all the keyword arguments coming\n",
    "        # from `ColorizedInputDescriber`:\n",
    "\n",
    "        ##### YOUR CODE HERE\n",
    "        decoder = ColorContextDecoder(\n",
    "            color_dim = self.color_dim,\n",
    "            vocab_size=self.vocab_size,\n",
    "            embed_dim=self.embed_dim,\n",
    "            hidden_dim=self.hidden_dim\n",
    "        )\n",
    "\n",
    "        # Return a `ColorizedEncoderDecoder` that uses\n",
    "        # your encoder and decoder:\n",
    "\n",
    "        ##### YOUR CODE HERE\n",
    "        return ColorizedEncoderDecoder(encoder, decoder)\n",
    "    \n",
    "class BertColorizedInputDescriber(ContextualColorDescriber):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, *kwargs)\n",
    "        self.idx2bertids = torch.tensor(bert_tokenizer.convert_tokens_to_ids(self.vocab))\n",
    "        \n",
    "    \n",
    "    def build_graph(self):\n",
    "        encoder = Encoder(\n",
    "            color_dim=self.color_dim,\n",
    "            hidden_dim=self.hidden_dim\n",
    "        )\n",
    "        \n",
    "        decoder = BertColorContextDecoder(\n",
    "            color_dim=self.color_dim,\n",
    "            idx2bertids=self.idx2bertids,\n",
    "            vocab_size=self.vocab_size,\n",
    "            embed_dim=BERT_EMBED_DIM,\n",
    "            hidden_dim=self.hidden_dim\n",
    "        )\n",
    "        \n",
    "        return BertEncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# toy_examples = dev_examples\n",
    "\n",
    "toy_rawcols, toy_texts = zip(*[[ex.colors, ex.contents] for ex in dev_examples[:500]])\n",
    "\n",
    "toy_rawcols_train, toy_rawcols_test, toy_texts_train, toy_texts_test = \\\n",
    "    train_test_split(toy_rawcols, toy_texts)\n",
    "\n",
    "del toy_rawcols, toy_texts#, toy_examples\n",
    "\n",
    "toy_seqs_train = [tokenize_example(s) for s in toy_texts_train]\n",
    "toy_seqs_test = [tokenize_example(s) for s in toy_texts_test]\n",
    "\n",
    "toy_cols_train = [represent_color_context(colors) for colors in toy_rawcols_train]\n",
    "toy_cols_test = [represent_color_context(colors) for colors in toy_rawcols_test]\n",
    "\n",
    "toy_vocab = ['[PAD]'] + sorted({w for toks in toy_seqs_train for w in toks}) + [UNK_SYMBOL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "shouldTrain = True\n",
    "\n",
    "if shouldTrain:\n",
    "    toy_model = BertColorizedInputDescriber(toy_vocab,\n",
    "                                        early_stopping=True,\n",
    "                                        freeze_embedding=True)\n",
    "\n",
    "    %time _ = toy_model.fit(toy_cols_train, toy_seqs_train)\n",
    "\n",
    "    with open(\"bert-finetuned-model.p\", \"wb\") as f:\n",
    "        pickle.dump(toy_model, f)\n",
    "        \n",
    "else:\n",
    "    with open(\"bert-finetuned-model.p\", \"rb\") as f:\n",
    "        toy_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8571428571428571, 1.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_model.listener_accuracy(toy_cols_train, toy_seqs_train),\\\n",
    "toy_model.listener_accuracy(toy_cols_test, toy_seqs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_seqs_train[0]\n",
    "bert_tokenizer.convert_tokens_to_ids(toy_seqs_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = toy_model.predict(toy_cols_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[CLS]', 'cam', '##o', 'green', '[SEP]'],\n",
       " ['[CLS]', 'neon', 'medium', 'pink', '[SEP]'],\n",
       " ['[CLS]', 'dark', '##ish', '##ish', 'red', '[SEP]']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[CLS]', 'cam', '##o', 'green', '[SEP]'],\n",
       " ['[CLS]', 'mint', 'green', '.', '[SEP]'],\n",
       " ['[CLS]', 'dark', '##ish', 'red', '[SEP]']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_seqs_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Since these modifications are pretty intricate, you might want to use [a toy dataset](colors_overview.ipynb#Toy-problems-for-development-work) to debug it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_full_system(describer_class):\n",
    "    toy_color_seqs, toy_word_seqs, toy_vocab = create_example_dataset(\n",
    "        group_size=50, vec_dim=2)\n",
    "\n",
    "    toy_color_seqs_train, toy_color_seqs_test, toy_word_seqs_train, toy_word_seqs_test = \\\n",
    "        train_test_split(toy_color_seqs, toy_word_seqs)\n",
    "\n",
    "    toy_mod = describer_class(toy_vocab)\n",
    "\n",
    "    _ = toy_mod.fit(toy_color_seqs_train, toy_word_seqs_train)\n",
    "\n",
    "    acc = toy_mod.listener_accuracy(toy_color_seqs_test, toy_word_seqs_test)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_full_system' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_184147/2356401602.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_full_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mColorizedInputDescriber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_full_system' is not defined"
     ]
    }
   ],
   "source": [
    "test_full_system(ColorizedInputDescriber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.convert_ids_to_tokens([0])\n",
    "bert_tokenizer.convert_tokens_to_ids(['[PAD]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that worked, then you can now try this model on SCC problems!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your original system [3 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many options for your original system, which consists of the full pipeline – all preprocessing and modeling steps. You are free to use any model you like, as long as you subclass `ContextualColorDescriber` in a way that allows its `evaluate` method to behave in the expected way.\n",
    "\n",
    "So that we can evaluate models in a uniform way for the bake-off, we ask that you modify the function `evaluate_original_system` below so that it accepts a trained instance of your model and does any preprocessing steps required by your model.\n",
    "\n",
    "If we seek to reproduce your results, we will rerun this entire notebook. Thus, it is fine if your `evaluate_original_system` makes use of functions you wrote or modified above this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_original_system(trained_model, color_seqs_test, texts_test):\n",
    "    \"\"\"\n",
    "    Feel free to modify this code to accommodate the needs of\n",
    "    your system. Just keep in mind that it will get raw corpus\n",
    "    examples as inputs for the bake-off.\n",
    "\n",
    "    \"\"\"\n",
    "    # `word_seqs_test` is a list of strings, so tokenize each of\n",
    "    # its elements:\n",
    "    tok_seqs = [tokenize_example(s) for s in texts_test]\n",
    "\n",
    "    col_seqs = [represent_color_context(colors)\n",
    "                for colors in color_seqs_test]\n",
    "\n",
    "\n",
    "    # Optionally include other preprocessing steps here. Note:\n",
    "    # DO NOT RETRAIN YOUR MODEL AS PART OF THIS EVALUATION!\n",
    "    # It's a tempting step, but it's a mistake and will get\n",
    "    # you disqualified!\n",
    "\n",
    "    # The following core score calculations are required:\n",
    "    evaluation = trained_model.evaluate(col_seqs, tok_seqs)\n",
    "\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `evaluate_original_system` works on test sets you create from the corpus distribution, then it will work for the bake-off, so consider checking that. For example, this would check that `dev_mod` above passes muster:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies. We also ask that you report the best **listener_accuracy** score your system got during development, just to help us understand how systems performed overall.\n",
    "\n",
    "<font color='red'>Please review the descriptions in the following comment and follow the instructions.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CS224U/cs224u/torch_model_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0mbatch_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_34609/289429249.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, color_seqs, word_seqs, seq_lengths, hidden, targets)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m##### YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         output, hidden = self.decoder(\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mword_seqs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mseq_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CS224U/cs224u/torch_color_describer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, word_seqs, seq_lengths, hidden, target_colors)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_colors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_colors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_34609/122894333.py\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(self, word_seqs, target_colors)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mtoken_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         )\n\u001b[0;32m--> 996\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 )\n\u001b[1;32m    584\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    586\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    514\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2470\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geewee/Documents/CS224U/cs224u/torch_color_describer.py:687: RuntimeWarning: divide by zero encountered in power\n",
      "  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n"
     ]
    }
   ],
   "source": [
    "# PLEASE MAKE SURE TO INCLUDE THE FOLLOWING BETWEEN THE START AND STOP COMMENTS:\n",
    "#   1) Textual description of your system.\n",
    "#   2) The code for your original system.\n",
    "#   3) The score achieved by your system in place of MY_NUMBER.\n",
    "#        With no other changes to that line.\n",
    "#        You should report your score as a decimal value <=1.0\n",
    "# PLEASE MAKE SURE NOT TO DELETE OR EDIT THE START AND STOP COMMENTS\n",
    "\n",
    "# NOTE: MODULES, CODE AND DATASETS REQUIRED FOR YOUR ORIGINAL SYSTEM\n",
    "# SHOULD BE ADDED BELOW THE 'IS_GRADESCOPE_ENV' CHECK CONDITION. DOING\n",
    "# SO ABOVE THE CHECK MAY CAUSE THE AUTOGRADER TO FAIL.\n",
    "\n",
    "# START COMMENT: Enter your system description in this cell.\n",
    "# For our original model, we pieced together many aspects of what was\n",
    "# taught in the homework into a fully working pipeline. We then trained\n",
    "# the resulting model on the full colors in context corpus to produce\n",
    "# our final model. Specifically, our model included the following:\n",
    "#\n",
    "# 1. We used the ideas from the Monroe et. al. 2017 paper to tokenize\n",
    "#    our inputs. We lowercased the entire string, removed any punctation,\n",
    "#    and then split on whitespace. We then removed the common endings of\n",
    "#    \"-er\", \"-est\" and \"-ish\" from all of our tokens. Once we had fully\n",
    "#    tokenized our training sequences, we then took another pass over\n",
    "#    those tokens to replaced any that only occured with the UNK_TOKEN.\n",
    "# 2. Instead of leaving our color representations as simple HLS values,\n",
    "#    we first converted those to HSV values and then applied the fourier\n",
    "#    transform described in Monroe et. al. 2016 to gives us some\n",
    "#    representations that are mapped on to a space more intuitive for \n",
    "#    how human understand colors.\n",
    "# 3. Next, we computed the glove embeddings for our vocab to give our\n",
    "#    model reasonable starting embeddings for our tokens.\n",
    "# 4. Finally, we fed our tokenized sequences, modified color\n",
    "#    representations, and initial glove embeddings into the Colorized\n",
    "#    Input Describer model that we built for Q4 of this homework.\n",
    "#    Training this on the full Stanford Colors in Context corpus gave us\n",
    "#    our final model that we submitted into the bakeoff.\n",
    "\n",
    "# My peak score was: 0.838\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    from collections import Counter\n",
    "\n",
    "    # Filters the training data so that any token that only appears once\n",
    "    # gets replaced by the unk token\n",
    "    def filter_vocab(seqs_train):\n",
    "        flat_list = [token for sequence in seqs_train for token in sequence]\n",
    "        vocab_count = Counter(flat_list)\n",
    "\n",
    "        for sequence in seqs_train:\n",
    "            for i, token in enumerate(sequence):\n",
    "                if vocab_count[token] <= 1:\n",
    "                    sequence[i] = UNK_SYMBOL\n",
    "                    \n",
    "    full_corpus = ColorsCorpusReader(\n",
    "        COLORS_SRC_FILENAME,\n",
    "        normalize_colors=True\n",
    "    )\n",
    "    full_examples = list(full_corpus.read())\n",
    "\n",
    "    full_rawcols, full_texts = zip(*[[ex.colors, ex.contents] for ex in full_examples])\n",
    "\n",
    "    full_rawcols_train, full_rawcols_test, full_texts_train, full_texts_test = \\\n",
    "        train_test_split(full_rawcols, full_texts)\n",
    "    \n",
    "    del full_rawcols, full_texts, full_examples\n",
    "\n",
    "    full_seqs_train = [tokenize_example(s) for s in full_texts_train]\n",
    "    full_seqs_test = [tokenize_example(s) for s in full_texts_test]\n",
    "\n",
    "    full_cols_train = [represent_color_context(colors) for colors in full_rawcols_train]\n",
    "    full_cols_test = [represent_color_context(colors) for colors in full_rawcols_test]\n",
    "\n",
    "    full_vocab = ['[PAD]'] + sorted({w for toks in full_seqs_train for w in toks}) + [UNK_SYMBOL]\n",
    "\n",
    "    shouldTrain = True\n",
    "    if shouldTrain:\n",
    "    \n",
    "        full_colorized_model = BertColorizedInputDescriber(\n",
    "            full_vocab,\n",
    "            early_stopping=True,\n",
    "            freeze_embedding=True)\n",
    "\n",
    "        %time _ = full_colorized_model.fit(full_cols_train, full_seqs_train)\n",
    "    \n",
    "        with open(\"bert-finetuned-model.p\", \"wb\") as f:\n",
    "            pickle.dump(full_colorized_model, f)\n",
    "\n",
    "    else:\n",
    "        with open(\"bert-finetuned-model.p\", \"rb\") as f:\n",
    "            full_colorized_model = pickle.load(f)\n",
    "\n",
    "    evaluation = evaluate_original_system(\n",
    "            full_colorized_model,\n",
    "            full_rawcols_test,\n",
    "            full_texts_test\n",
    "        )\n",
    "\n",
    "    print(evaluation['listener_accuracy'])                    \n",
    "                    \n",
    "# STOP COMMENT: Please do not remove this comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bakeoff [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the bake-off, we will use our original test set. The function you need to run for the submission is the following, which uses your `evaluate_original_system` from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bakeoff_submission(\n",
    "        trained_model,\n",
    "        output_filename='cs224u-colors-bakeoff-entry.csv'):\n",
    "    bakeoff_src_filename = os.path.join(\n",
    "        \"data\", \"colors\", \"cs224u-colors-test.csv\")\n",
    "\n",
    "    bakeoff_corpus = ColorsCorpusReader(bakeoff_src_filename)\n",
    "\n",
    "    # This code just extracts the colors and texts from the new corpus:\n",
    "    bakeoff_rawcols, bakeoff_texts = zip(*[\n",
    "        [ex.colors, ex.contents] for ex in bakeoff_corpus.read()])\n",
    "\n",
    "    # Original system function call; `trained_model` is your trained model:\n",
    "    evaluation = evaluate_original_system(\n",
    "        trained_model, bakeoff_rawcols, bakeoff_texts)\n",
    "\n",
    "    evaluation['bakeoff_text'] = bakeoff_texts\n",
    "\n",
    "    df = pd.DataFrame(evaluation)\n",
    "    df.to_csv(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This check ensure that the following code only runs on the local environment only.\n",
    "# The following call will not be run on the autograder environment.\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    pass\n",
    "    create_bakeoff_submission(full_colorized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a file `cs224u-colors-bakeoff-entry.csv` in the current directory. That file should be uploaded as-is. Please do not change its name.\n",
    "\n",
    "Only one upload per team is permitted, and you should do no tuning of your system based on what you see in the file – you should not study that file in anyway, beyond perhaps checking that it contains what you expected it to contain. The upload function will do some additional checking to ensure that your file is well-formed.\n",
    "\n",
    "The nature of our evaluation is such that we have to release the full test set with all labels. Thus, we have to trust you not to make any use of the test set during development. Recall:\n",
    "\n",
    "1. Only one evaluation is permitted.\n",
    "1. No additional system tuning is permitted once the bake-off has started.\n",
    "\n",
    "Systems will be ranked primarily by `listener_accuracy`, but we will also consider their `corpus_bleu` scores. However, the BLEU score is just a simple check that your system is speaking some version of English that corresponds in some meaningful way to the gold descriptions, so you should concentrate on `listener_accuracy`.\n",
    "\n",
    "People who enter will receive the additional homework point, and people whose systems achieve the top score will receive an additional 0.5 points. We will test the top-performing systems ourselves, and only systems for which we can reproduce the reported results will win the extra 0.5 points.\n",
    "\n",
    "Late entries will be accepted, but they cannot earn the extra 0.5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instruction\n",
    "\n",
    "Review and follow the [Homework and bake-off code: Formatting guide](hw_formatting_guide.ipynb).\n",
    "Please do not change the file name as described below.\n",
    "\n",
    "Submit the following files to Gradescope:\n",
    "\n",
    "- `hw_colors.ipynb` (this notebook)\n",
    "- `cs224u-colors-bakeoff-entry.csv` (bake-off output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
